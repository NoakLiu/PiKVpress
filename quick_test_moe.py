#!/usr/bin/env python3
"""
å¿«é€Ÿæµ‹è¯•MoEè·¯ç”±å™¨Press
"""

import torch
from kvpress.presses import MoERouterPress

def test_moe_router():
    """æµ‹è¯•MoEè·¯ç”±å™¨çš„åŸºæœ¬åŠŸèƒ½"""
    print("=== æµ‹è¯•MoEè·¯ç”±å™¨Press ===")
    
    # åˆ›å»ºMoEè·¯ç”±å™¨Press
    moe_press = MoERouterPress(
        num_experts=4,
        top_k=2,
        router_type="pikv",
        cache_aware=True
    )
    
    print(f"âœ“ MoEè·¯ç”±å™¨Pressåˆ›å»ºæˆåŠŸ")
    print(f"  - ä¸“å®¶æ•°é‡: {moe_press.num_experts}")
    print(f"  - Top-K: {moe_press.top_k}")
    print(f"  - è·¯ç”±å™¨ç±»å‹: {moe_press.router_type}")
    print(f"  - ç¼“å­˜æ„ŸçŸ¥: {moe_press.cache_aware}")
    
    # æµ‹è¯•è·¯ç”±å™¨åˆ›å»º
    router = moe_press._get_router(layer_idx=0, hidden_size=512)
    print(f"âœ“ è·¯ç”±å™¨åˆ›å»ºæˆåŠŸ: {type(router).__name__}")
    
    # æµ‹è¯•å‰å‘ä¼ æ’­
    hidden_states = torch.randn(2, 10, 512)
    dispatch_tensor, combine_tensor, router_probs, aux_loss = router(hidden_states)
    
    print(f"âœ“ å‰å‘ä¼ æ’­æˆåŠŸ")
    print(f"  - è°ƒåº¦å¼ é‡å½¢çŠ¶: {dispatch_tensor.shape}")
    print(f"  - ç»„åˆå¼ é‡å½¢çŠ¶: {combine_tensor.shape}")
    print(f"  - è·¯ç”±æ¦‚ç‡å½¢çŠ¶: {router_probs.shape}")
    print(f"  - è¾…åŠ©æŸå¤±: {aux_loss.item():.4f}")
    
    # æµ‹è¯•å‹ç¼©ç­–ç•¥
    keys = torch.randn(2, 8, 100, 64)
    values = torch.randn(2, 8, 100, 64)
    
    for strategy in ["aggressive", "moderate", "conservative", "selective"]:
        compressed_keys, compressed_values = moe_press._apply_expert_compression(
            keys, values, strategy, router_probs
        )
        compression_ratio = (keys.shape[2] - compressed_keys.shape[2]) / keys.shape[2]
        print(f"âœ“ {strategy}ç­–ç•¥: {keys.shape[2]} -> {compressed_keys.shape[2]} (å‹ç¼©æ¯”: {compression_ratio:.2f})")
    
    # æµ‹è¯•ç»Ÿè®¡ä¿¡æ¯
    stats = moe_press.get_stats()
    print(f"âœ“ ç»Ÿè®¡ä¿¡æ¯è·å–æˆåŠŸ")
    print(f"  - å‰å‘ä¼ æ’­æ¬¡æ•°: {stats['forward_count']}")
    print(f"  - å¹³å‡è¾…åŠ©æŸå¤±: {stats['avg_aux_loss']:.4f}")
    
    print("\n=== æ‰€æœ‰æµ‹è¯•é€šè¿‡! ===")

def test_with_mock_model():
    """ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å‹æµ‹è¯•"""
    print("\n=== æ¨¡æ‹Ÿæ¨¡å‹æµ‹è¯• ===")
    
    from unittest.mock import Mock
    
    # åˆ›å»ºæ¨¡æ‹Ÿæ¨¡å—
    mock_module = Mock()
    mock_module.layer_idx = 0
    
    # åˆ›å»ºMoEè·¯ç”±å™¨Press
    moe_press = MoERouterPress(num_experts=4, router_type="base")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    hidden_states = torch.randn(2, 10, 512)
    keys = torch.randn(2, 8, 100, 64)
    values = torch.randn(2, 8, 100, 64)
    attentions = torch.randn(2, 8, 10, 100)
    kwargs = {}
    
    # æ‰§è¡Œå‹ç¼©
    compressed_keys, compressed_values = moe_press.compress(
        mock_module, hidden_states, keys, values, attentions, kwargs
    )
    
    print(f"âœ“ å‹ç¼©æˆåŠŸ")
    print(f"  - åŸå§‹KVå½¢çŠ¶: {keys.shape}")
    print(f"  - å‹ç¼©åKVå½¢çŠ¶: {compressed_keys.shape}")
    print(f"  - å‹ç¼©æ¯”ä¾‹: {(keys.shape[2] - compressed_keys.shape[2]) / keys.shape[2]:.2f}")
    
    # è·å–è¯¦ç»†ç»Ÿè®¡
    stats = moe_press.get_stats()
    print(f"âœ“ è¯¦ç»†ç»Ÿè®¡:")
    print(f"  - æ€»è¾…åŠ©æŸå¤±: {stats['total_aux_loss']:.4f}")
    print(f"  - å‰å‘ä¼ æ’­æ¬¡æ•°: {stats['forward_count']}")
    
    if stats['layer_stats']:
        layer_0_stats = stats['layer_stats'][0]
        expert_usage = layer_0_stats['expert_compression_stats']['expert_usage']
        print(f"  - ä¸“å®¶ä½¿ç”¨æƒ…å†µ: {expert_usage.tolist()}")

if __name__ == "__main__":
    try:
        test_moe_router()
        test_with_mock_model()
        print("\nğŸ‰ MoEè·¯ç”±å™¨Pressæµ‹è¯•å®Œæˆ!")
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc() 